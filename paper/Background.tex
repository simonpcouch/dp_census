\section{Background} \label{sec:background}


\subsection{The U.S. Census}\label{sec:census}

Article I, Section II of the U.S. Constitution mandated that an ``actual enumeration'' of the U.S. population should take place every ten years. The first census was taken in 1790, and since 1903, the Bureau has undertaken significant efforts not only to collect this data, but to distribute it in a useful and comprehensive manner. Resultantly, the Bureau now publishes billions of statistical summaries of this data following every decennial census for uses in legislative redistricting, distributing ``more than \$675 billion in federal funds,'' and social research, to name a few \cite{bureau_us_2020}.

The data is released at varying levels of detail: by nation, region, division, state, and county. The census also designates its own finer levels of observation: census tracts, block groups, and blocks. The census block group, which is the second smallest level of observation published by the Bureau and is increasingly a unit of analysis in social research, is the degree of detail centered in this paper: these areas can generally be imagined as, in a city, a literal group of city blocks, generally containing in the range of 900 to 1400 people (though possibly containing no people at all or tens of thousands) \cite{bureau_us_2020}.

\subsection{The Problem of Privacy}\label{sec:privacy}

The Bureau faces a dual mandate to publish summaries of the data they collect that are both accurate and protective of respondent privacy. These mandates are not just customary, but enshrined in law \cite{code_title_1954, code_title_2002}. The strategies employed by the census to protect respondent privacy in practice are referred to as `disclosure avoidance processes.'

In past censuses, disclosure avoidance was largely an ad-hoc procedure carried out at the discretion of Bureau analysts, consisting of `swapping' households from one block to another or adding small amounts of mathematical randomness to population counts. These procedures were critically important for respondents who might be, for example, the only whom identified with some racial category in a census block. As a result, analysts who wished to uncover information about specific respondents would be unable to discern whether some entry in published statistics truly represented the presence of a known respondent or was the result of the swapping of households or addition of noise. In the past, the guidelines for carrying out these procedures, as well as clarification on which data products are impacted by this process, remained internal to the Bureau \cite{boyd_balancing_2020}.

Recently, however, it has become clear that improvised or arbitrarily determined privatization techniques are not sufficient to protect respondent privacy. The swaths of data that the census publishes, as with any data, are vulnerable to database reconstruction attacks, whereby some attacker attempts to reconstruct the `original' data from its summaries by combining the data with other data summaries as well as third-party data sources. (Third-party data sources might include state records or personal data collected from smartphones.) More data available for attackers to combine with census data means a greater probability that attackers will be able to transform statistical summaries into individual records. In other words, it is possible that, with enough detailed data on a sensitive population, one may be able to reverse engineer the underlying data used to generate the summaries, and thus reveal sensitive information about individual respondents. Taken in conjunction, the massive increase in computing power available to individuals and data on people hosted throughout the internet means that the results of the Census are increasingly vulnerable to reconstruction attacks \cite{boyd_balancing_2020, abowd_economic_2019}. In realization of this risk, the Bureau announced in 2018 that it would be taking further steps to protect respondent privacy.

\subsection{Differential Privacy}\label{sec:dp}

Differential privacy is an emerging field at the intersection of statistics and computer science. Differentially private algorithms seek to optimize the statistical utility of (in this case) data summarizations while also mathematically provably protecting the privacy of individuals. They do so by guaranteeing that statistical summaries will not change `too much' depending on whether a specific individual is in the dataset or not, where the notion of `too much' is parameterized by an epsilon $\epsilon$ value sometimes referred to as a `privacy-loss budget.' To carry this out, algorithms add small amounts of noise to the true outputted statistics in order to produce public data summaries. Thus, the consumer of the differentially private estimates cannot be certain whether the relationships in a set of summary values are due to the presence of a specific individual in the database, or are simply the result of the addition of random noise. As a result, though, there is inherently a trade-off between confidentiality and statistical utility.

The Bureau's choice of differentially private algorithms offers several unique advantages over the previous approach:

\begin{itemize}
  \item \textit{Robust to post-processing}: Differentially private algorithms are robust to post-processing, meaning that the privacy guarantee of an algorithm is not comprimised by processing (e.g. rounding population counts to the nearest whole number or rounding negative population counts up to zero) the outputted data as long as the original, true values are not accessed as part of the computation. This also means that the Bureau can adjust for what it terms \textit{invariants}, which are certain selected values whose true value must remain unaltered. For example, the Bureau could scale privatized county population counts to ensure that they add up to the total state population.
  \item \textit{Public}: Unlike the Bureau's previous approach, all details of the implementation of the differentially private algorithm can be made available without comprimising the privacy guarantee. This will allow for analyses based on the released data to statistically account for the addition of noise. This also means that the code used to implement the Bureau's algorithm can be publicly vetted for accuracy and rigor.
  \item \textit{Straightforward Composition}: When a statistic is derived from combining the output of an $\epsilon_1$-differentially private algorithm and an $\epsilon_2$-differentially private algorithm, that statistic is at most $\epsilon_1 + \epsilon_2$-differentially private. This means that the Bureau can release as many $\epsilon_i$-differentially private summaries as necessary, and can straightforwardly guarantee that the complete data product is ($\sum_i \epsilon_i$)-differentially private.
\end{itemize}

Since the Bureau's announcement of this decision, there has been considerable resistance from a variety of stakeholders---for many, ``the idea that data utility and privacy can be operationalized into a mathematical trade-off is both unfathomable and deeply unsettling'' \cite{boyd_balancing_2020}. In Section \ref{sec:results}, I will argue that this wariness is well-founded.

% Those who have been deeply invested in understanding the details of the census know that disclosure avoidance mechanisms have always introduced some noise into the system, but the bureau has always maintained that the noise purposefully introduced is very small compared to the noise that comes from mistakes, imputation, and other forms of human error. Data users have accepted – or, in some cases, not known about – this reality. \cite{boyd_balancing_2020}

\subsection{Census Racial Categories}\label{sec:race-cats}

In the social sciences, it is well-accepted that race and ethnicity are socially constructed categorizations. Considerable work has been devoted to examining exactly what it means for such socially salient concepts to be social constructions \cite{lee2009race, omi_racial_2014}, largely converging in their consensus that historical theorizing on race ``has been part and parcel of rac\textit{ism}'' \cite{morning2011nature}. ``Since its invention to manage the expansion of European enslavement and the colonization of other peoples, the definitions, criteria, and boundary lines that determine racial categories have constantly shifted over the course of U.S. history'' \cite{roberts2011fatal}. The decennial census is a unique window into this history, exemplifying the instability and arbitrariness of racial categorizations. 

Every decade since the first census in 1790, the Bureau has somehow altered the `race question,' whether it be in its phrasing, the categories offered, or instructions on choosing them \cite{strmic-pawl_race_2018}. Many have written on this history \cite{espiritu_asian_1992, prewitt_what_2013, strmic-pawl_race_2018, hochschild_racial_2008}, and conclusions are shared among many theorists: ``For the majority of the existence of the census, Whiteness and power motivated the addition and removal of racial groups, the names for racial groups, and the use of census officials to observe and record the race of participants,'' and, consequently, ``the categories have been arbitrary and inconsistent---often reflecting the Census Bureau’s administrative needs rather than the population's perceptions of meaningful cultural and racial differentiations'' \cite{espiritu_asian_1992, strmic-pawl_race_2018}. Pre-civil rights era, the inclusion of racial categorizations in the census was largely a tool for subordination, but after the 1960s, the bureau adopted a ``social equity ideology'' \cite{strmic-pawl_race_2018}. The latter half of the 20th century, especially, saw significant variation in the construction of Asian and Hispanic categorizations, and the terminology used to refer to them (whether racial, ethnic, ethno-racial, or the more self-aware ``super-ethnic'') \cite{espiritu_asian_1992, choldin_statistics_1986}. This reorientation is not simply a reflection of organizational conscience; the U.S. Commission on Civil Rights ``stated that racial and ethnic classification can be justified only if the data produced have a legitimate use in terms of combating discrimination, planning programs, or conducting program evaluation'' \cite{humes_measurement_2009}. We can thus see that the Bureau’s choice of racial categorizations is situationally determined--I also argue that this choice is highly consequential.

\subsection{``Race Counts''}\label{sec:race-counts}

Not only is accurate census count mandated in Article I, section II of the U.S. Constitution, but it is an absolute necessity for the functioning of democracy. Accurate census counts by race bear on the electoral process, claims of discrimination, the distribution of money to local governments and grant applicants, and research in a plethora of fields. 

For one, population statistics are used to ensure fairness in accessibility to the electoral process. The 1975 Voting Rights Act requires that ``bilingual assistance must be available in voting districts in which more than 5 percent of the citizens are members of the affected language minority group'' \cite{espiritu_asian_1992}. Counts by race, then, were especially important in planning for the 1980 census, where, because the 1970 census did not ask about languages spoken in the home, racial statistics were used as a proxy for language accessibility needs \cite{keane_increasing_1985}. Since then, too, if one grants that non-English-speaking needs are not equally distributed among census racial categories, an inaccurate count by race implies an inaccurate understanding of language accessibility needs. Not to mention, too, that beyond language accessibility needs, census counts directly determine the apportionment of seats in Congress.

Additionally, underrepresentation is the basis of many affirmative action cases, and proportions by race based on census enumeration have successfully been used as evidence in such cases \cite{harris_whiteness_2003, espiritu_asian_1992, choldin_statistics_1986}.

Further, population counts ``bear directly on the distribution of federal monies to states, counties, and cities for everything from feeding the poor to running mass transit systems.''  Similarly, billions of dollars a year in grant money are distributed at least in part according to census counts, especially those figures that are tied to economic and health disparities \cite{espiritu_asian_1992}.

% in coming together to lobby for more thoughtful and comprehensive representation in the 1990 U.S. census, Asian Americans ``did not merely accept the pan-Asian concept imposed by outsiders but also used it to advance their political demands—including the demand that government bureaucracies treat them as separate groups within a larger category.'' \cite{espiritu_asian_1992}

% ``Local public officials also entered into the undercount controversy. Besides affecting the apportionment of seats in Congress, seats in state legislatures, and even city council distncts, census population counts bear directly on the distribution of federal monies to states, counties, and cities for everything from feeding the poor to running mass transit systems.'' \cite{maurice_census_1982}

\subsection{A Note: Defining Race}\label{sec:defining-race}

In this paper, my use of the term `race' will largely mirror that of Prewitt's \textit{statistical race}: ``Organized counting of any kind---and certainly a census is organized counting---requires counters to know what they are counting, which in turn depends on a classification scheme. Statistical races are by-products of the categories used in the government’s racial classification.'' \cite{prewitt_what_2013} The statistical races (and ethnicities) referenced in this paper, then, are those that result from the 2010 and 2020 census racial classifications. It is worth noting that the census' use of the term race refers to an undifferentiated conglomeration of definitions and concepts invoking biological race \cite{prewitt_what_2013, quisumbing_king_recentering_2019}, ethnicity and panethnicity \cite{omi_racial_2014, espiritu_asian_1992, espiritu_who_2000}, nationality \cite{mezey_erasure_2002}, and existing sovereign nationhood \cite{byrd_been_2011}. Further, consistent with the Bureau's current analytical approach \cite{pack_note_1996, fox_differential_2018}, I will consider respondents who identify as non-Hispanic/Latino ethnically and white racially as white people, and those who do not as people of color, as binary analytical categories in some analyses in Section \ref{sec:results}. The relationship between statistical races and whatever phenomenon they proxy is left to Section \ref{sec:disc}.
  

\subsection{The Differential Undercount}

Some of the census statistics use cases in Section \ref{sec:race-counts} may not seem, at the surface, inherently racialized. This is not the case, though, given the existence of ``differential undercounts,'' where the counts of certain population segments are systematically lower than their actual count to a greater proportion than other segments. That is, the severity with which population groups are not sufficiently counted is not evenly distributed amongst age groups, geographic areas, gender identities, races, ethnicities, and tribal statuses. Notably, ``the undercount rate for racial and ethnic minority groups is substantially higher than the undercount rate for other demographic criteria'' \cite{fox_differential_2018}. Indeed, ``[t]he 1990 census also missed more minorities than whites, undercounting about 5 percent of blacks and Latinos while overlooking fewer than 2 percent of whites'' \cite{espiritu_asian_1992}. Given this fact, and the continuing severity of geographic segregation in the U.S. \cite{bonilla-silva_racism_2010}, \textit{any} count inaccuracy is inherently racialized. 

There are several sources contributing to a racialized differential undercount. Principally, recent literature has pointed to the well-founded fears of minorities in disclosing membership in marginalized groups. Distrust of the Bureau, and the U.S. government in general, is often argued to contribute significantly to the differential undercount, especially in reference to (recently) historical disclosures of constitutionally protected confidential information on the part of the Bureau to other divisions in the Executive Branch. Especially in light of recent violences perpetrated by the Trump administration, as well as the debate on the addition of a citizenship question to the 2020 Census, scholars predict that ``Hispanic distrust of the government will lead to an unprecedented differential undercount in the 2020 Census'' \cite{fox_differential_2018}. See Section \ref{sec:disc} for more discussion of Bureau disclosures of constitutionally protected information and enabling of government-perpetrated violences.

\subsection{Color-Blind Racism}\label{sec:color-blind}

In his oft-cited book \textit{Racism Without Racists}, Eduardo Bonilla-Silva describes the ideology of \textit{color-blind racism}, referring to the dominant and powerfully dismissive American racial ideology that ``explains contemporary racial inequality as the outcome of nonracial dynamics'' \cite{bonilla-silva_racism_2010}. Assuming the absence of institutionalized racism and refusing to reconcile persistent racialized inequality beyond blaming ``imputed cultural limitations,'' this framing holds to the abstractly liberal ideas of universalism and equality, claiming that color-blind efforts to address economic inequality will benefit all equally. As Justice Roberts famously wrote in his plurarity opinion on Parents Involved in Community Schools v. Seattle School District No. 1, this ideology would agree that ``[t]he way to stop discrimination on the basis of race is to stop discriminating on the basis of race.'' 

The Bureau's implementation of differentially private algorithms to estimate the results of the 2020 U.S. Census is a glaring example of color-blind racism. These algorithms will be used to estimate the population counts of people in the U.S. by race and ethnicity in a color-blind manner, meaning that the same amount of mathematical randomness will be added to all racial and ethnic subgroup counts. Given the racial taxonomy used by the Bureau, though, on average, there will be significantly fewer people identifying with a given ethnoracial subgroup other than White non-Hispanic/Latino than there will be those who identify with the White non-Hispanic/Latino subgroup. As a result, since the same amount of noise is added to each subgroup count, the estimates for subpopulations of people of color will be significantly worse than those for white people.

A simulation of this phenomenon is shown in Figure \ref{fig:dif-priv}. This figure supposes two hypothetical populations, A and B, for which the true population counts are 50 and 1000, respectively. Supposing that the populations were counted correctly, the counts are processed using a `differentially-private' algorithm, where the same amount of noise is added to both population counts. However, this noise is much more meaningful for population A, with estimated population counts sometimes dipping into the negatives, and often being half or twice the actual population size. This same error distribution for population B, however, by proportion, is much less meaningful; underestimating a population count of 50 by 50 is a much more drastic change than underestimating a population count of 1000 by 50. If these population counts were counts by race, then, the issue of a color-blind algorithm (and, possibly, the use of this class of algorithm in general) becomes clear. 

\begin{figure}[ht]
   \centering
   \includegraphics[width=0.75\textwidth]{figures/dif_priv.png}
   \caption{Distributions of `differentially private' population count estimates for hypothetical populations A and B, with respective true population counts of 50 and 1000. The variance of the error in each distribution is identical, but is much more meaningful for the accuracy of the estimate for population A than for B.}
   \label{fig:dif-priv}
\end{figure}

How does this hypothetical scenario play out in practice, though? I will show in Section \ref{sec:results} that the implementation of this privatization algorithm for use in the 2020 U.S. Census is a particularly egregious example of color-blind racism in action. This decision by the Bureau will disproportionately negatively impact people of color, and, further, if Fox \cite{fox_differential_2018} was correct in arguing that the differential undercount already likely in the 2020 U.S. Census undermines Article I, Section II of the U.S. Constitution, then so too is the implementation of differentially private algorithms for use in privatizing the results of the 2020 U.S. Census.

% Let not the irony be lost of the census choosing a class of privatization algorithms called ``differentially private'' that will aggravate the differential undercount problem.

