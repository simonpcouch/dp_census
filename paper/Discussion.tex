\section{Discussion}\label{sec:disc}

In the preceding section, I showed that the quality of differentially private population count estimates for populations of color at the census block group level is unacceptable at best. This result leaves much to be said to make meaning of these inaccuracies and consider possible remedies. My considerations of these problems omit the possibility of the most obvious solution: better algorithms. As many working on these problems have noted, however, the time to wait for technical innovation is not a luxury that is available to the Bureau.

Before the announcement that the Bureau would be using differentially private algorithms to privatize their data products, significant research was already being carried out making meaning of the racialized differential undercount. Specifically, several authors centered the question of how to structure ``the race question'' to most effectively inform social justice efforts within practical constraints.

One consideration coming out of this literature is to more closely examine the relationship between contempary understandings of racialized identity and the form of `the race question.' Does the Census' race definition need to reflect ``the population's perceptions of meaningful cultural and racial differentiations'' in order to most effectively serve its supposed new purpose of advancing social equity \cite{espiritu_asian_1992}? For one, census racial categorizations ought to be sensitive to previous (mis)uses of census racial data as well as the current political climate. In light of recent violences perpetrated by ICE and the Trump administration on Latinx people \cite{fox_differential_2018}, and the Bureau's role in surveillance of Arab Americans post-9/11 \cite{beydoun_demographic_2015}, Japanese American internment \cite{anderson_public_2015}, and displacement of Native Americans, ``all minorities share equally in the fear of answering race, ethnicity, and citizenship questions on the census'' \cite{fox_differential_2018}. If the ultimate end of the development and maintenance of census racial categories is the effective tracking of social inequality, and the identification with some specific racial and ethnic groups exacerbates an already severe differential undercount of racial and ethnic minorities, then the most effective categorizations might not necessarily reflect lived contemporary racial identity. As Fox wrote in a recent article on the differential undercount, ``[i]f you are in some other category a decade later, and millions are, you have changed your mind. Racial identity in the census is not whether a taxi stops for you, or what is on your birth certificate, or what your grandparents thought they were. It is a tick in a box.'' \cite{fox_differential_2018}

Further, too, what is a privacy promise worth when the Bureau systematically violates this promise? As mentioned earlier, the Bureau has violated its confidentiality promise by distributing census data throughout executive branch departments on multiple occasions. (See \cite{fox_differential_2018} for an exhaustive list of examples.) Historically, the Bureau has shown that it is incapable of truthfully promising confidentiality to constituents. Why, then, feign a struggle to reconcile privacy and statistical utility when the former is simply not a promise that the Bureau can make? In this way, the effect of the implementation of a `privacy-protection' algorithm---especially one that disproportionately harms people of color---seems futile at best, and gravely harmful at worst. Given that the Bureau has consistently failed to follow through on its commitment to respondent privacy, the census ought to reflect information that the constituency is comfortable being made public, and the Bureau should focus on ensuring that this data is as accurate as possible to fulfill its obligation to Article I, Section 2 of the constitution. Otherwise, significant efforts need to be undertaken to ensure respondent privacy beyond the narrow realm of reconstruction attacks and address the increasing risk of an unprecedented differential undercount. ``With this understanding of history and likely future practice, only a constitutional amendment barring government census disclosures will ensure that all residents may comfortably participate in the U.S. Census'' \cite{fox_differential_2018}. Otherwise, we must reckon with unrepresentativeness that will ``weaken policy choices relevant to economic growth, social justice, immigrant assimilation, government reforms, and an enlightened public'' \cite{prewitt_census_2018}.

Another possibility is the reconsideration of the geographic precision at which to release these statistics. Though data at the census block level is desired by many stakeholders, this level of detail is increasingly a risk to respondent confidentiality. As a result, too, the portion of the $\epsilon$ budget alloted to estimating block-level statistics could be reallocated to estimating other statistics, thereby increasing the quality of the published data \cite{boyd_balancing_2020}.

This study is limited in several key ways. Notably, for one, I only analyzed simulation data at the census block group level. With Figure \ref{fig:dif-priv} in mind, the results from the block group level are a (second-to) worst-case evaluation of the effects of the implementation of these algorithms. As population counts grow larger, the effect of privatization on the utility of these numbers will decrease. A more detailed study would examine each level of geographical organization, examining the effects of privatization at each level and discussing the implications for use cases of data especially relevant to that level of aggregation. Further, this paper makes use of the output of an existing algorithmic implementation. Further work would more closely consider the effect of varying parameterizations through the simulation of original datasets with many different choices of the total $\epsilon$ privacy budget and allocation of $\epsilon$ to different statistics, as well as run several iterations of the simulations in order to allow for more detailed study of the variation of the statistics describing specific geographic regions.

Altogether, I have argued that the implementation of differentially private algorithms to estimate subpopulation counts in the 2020 U.S. will have a disproportionately negative impact on the quality of count estimates of populations of color. This effect will exacerbate the existing differential undercount problem, where the Bureau systematically undercounts populations of color more so than it does for white populations.



